{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSoVz08BQFYDG81y0bLJRB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## SETUP"],"metadata":{"id":"KkK9P029ciBG"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRxjS2qvcdzj","executionInfo":{"status":"ok","timestamp":1755795434379,"user_tz":-120,"elapsed":58367,"user":{"displayName":"Carlos Romero","userId":"09804593201902616528"}},"outputId":"9d057ef5-2ea1-4f39-d1a2-d819def5bfeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n","  warnings.warn(\n"]}],"source":["# Monta Drive, define rutas y carga vocab+modelo; helpers de normalizaciÃ³n, transposiciÃ³n y predicciÃ³n.\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","except Exception:\n","    pass\n","\n","import os, json, math, re, ast\n","from dataclasses import dataclass\n","from typing import List, Tuple\n","import numpy as np\n","import torch, torch.nn as nn, torch.nn.functional as F\n","\n","# --- Rutas y constantes ---\n","BASE_DIR   = \"/content/drive/MyDrive/Colab Notebooks/TFG\"\n","DATA_DIR   = os.path.join(BASE_DIR, \"Archivos preprocesamiento\")\n","MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n","MAX_LEN = 112\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# --- Carga vocab y config ---\n","with open(os.path.join(DATA_DIR, \"chord_to_idx.json\"), \"r\", encoding=\"utf-8\") as f: CH2IDX = json.load(f)\n","with open(os.path.join(DATA_DIR, \"idx_to_chord.json\"), \"r\", encoding=\"utf-8\") as f: IDX2CH = json.load(f)\n","PAD, UNK = CH2IDX[\"[PAD]\"], CH2IDX[\"[UNK]\"]\n","with open(os.path.join(MODELS_DIR, \"config.json\"), \"r\", encoding=\"utf-8\") as f: CFG_JSON = json.load(f)\n","\n","# --- Modelo (mismos nombres que en el entrenamiento) ---\n","from dataclasses import dataclass\n","import torch.nn as nn\n","\n","@dataclass\n","class ModelConfig:\n","    vocab_size: int; pad_idx: int; unk_idx: int; max_len: int = MAX_LEN\n","    d_model: int = 256; n_layers: int = 4; n_heads: int = 8; d_ff: int = 1024; dropout: float = 0.1\n","\n","class PositionalEmbedding(nn.Module):\n","    # Debe llamarse pos_emb por dentro (coincide con el checkpoint)\n","    def __init__(self, max_len, d_model):\n","        super().__init__()\n","        self.pos_emb = nn.Embedding(max_len, d_model)\n","    def forward(self, x):\n","        B, T = x.size()\n","        pos = torch.arange(T, device=x.device).unsqueeze(0).expand(B, T)\n","        return self.pos_emb(pos)\n","\n","class CausalTransformer(nn.Module):\n","    # Capas con los mismos nombres: tok_emb, pos_emb, lm_head\n","    def __init__(self, cfg: ModelConfig):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg.vocab_size, cfg.d_model, padding_idx=cfg.pad_idx)\n","        self.pos_emb = PositionalEmbedding(cfg.max_len, cfg.d_model)\n","        enc = nn.TransformerEncoderLayer(d_model=cfg.d_model, nhead=cfg.n_heads,\n","                                         dim_feedforward=cfg.d_ff, dropout=cfg.dropout,\n","                                         activation=\"gelu\", batch_first=True, norm_first=True)\n","        self.trf = nn.TransformerEncoder(enc, num_layers=cfg.n_layers)\n","        self.drop = nn.Dropout(cfg.dropout)\n","        self.lm_head = nn.Linear(cfg.d_model, cfg.vocab_size)\n","        self.apply(self._init_w)\n","    def _causal_mask(self, T, device):\n","        return torch.triu(torch.ones(T, T, device=device, dtype=torch.bool), diagonal=1)\n","    def _init_w(self, m):\n","        if isinstance(m, (nn.Linear, nn.Embedding)):\n","            nn.init.normal_(m.weight, 0.0, 0.02)\n","        if isinstance(m, nn.Linear) and m.bias is not None:\n","            nn.init.zeros_(m.bias)\n","    def forward(self, x, attention_mask=None):\n","        B, T = x.shape\n","        h = self.drop(self.tok_emb(x) + self.pos_emb(x))\n","        causal = self._causal_mask(T, x.device)\n","        key_pad = (attention_mask == 0) if attention_mask is not None else None\n","        h = self.trf(h, mask=causal, src_key_padding_mask=key_pad)\n","        return self.lm_head(h)\n","\n","# Instanciar y cargar checkpoint (ahora sÃ­ casan las claves)\n","CFG = ModelConfig(vocab_size=len(CH2IDX), pad_idx=PAD, unk_idx=UNK,\n","                  max_len=int(CFG_JSON.get(\"max_len\", MAX_LEN)),\n","                  d_model=int(CFG_JSON.get(\"d_model\", 256)),\n","                  n_layers=int(CFG_JSON.get(\"n_layers\", 4)),\n","                  n_heads=int(CFG_JSON.get(\"n_heads\", 8)),\n","                  d_ff=int(CFG_JSON.get(\"d_ff\", 1024)),\n","                  dropout=float(CFG_JSON.get(\"dropout\", 0.1)))\n","\n","MODEL = CausalTransformer(CFG).to(device)\n","CKPT  = torch.load(os.path.join(MODELS_DIR, \"checkpoint_best.pt\"), map_location=device)\n","MODEL.load_state_dict(CKPT[\"model_state\"], strict=True)\n","MODEL.eval()\n","\n","# --- Helpers: normalizar notaciÃ³n, parsear raÃ­z/extensiÃ³n y transponer ---\n","NOTE_SH = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n","VAL = {n:i for i,n in enumerate(NOTE_SH)}; VAL.update({'Db':1,'Eb':3,'Gb':6,'Ab':8,'Bb':10})\n","REV = {i:n for i,n in enumerate(NOTE_SH)}\n","\n","def norm_ch(s:str)->str:\n","    # NotaciÃ³n compacta tÃ­pica del dataset.\n","    return s.replace(\"min\",\"m\").replace(\"maj\",\"M\").replace(\"s\",\"#\").strip()\n","\n","class ExtChord:\n","    # root + (optional) 'm' + resto (p.ej., '7', 'maj7', 'sus4'â€¦)\n","    __slots__=(\"root\",\"quality\",\"ext\")\n","    def __init__(self, c:str):\n","        m = re.match(r\"^([A-G][b#]?)(.*)$\", c)\n","        if not m: self.root=self.quality=self.ext=None; return\n","        self.root = m.group(1); rem = m.group(2)\n","        if rem.startswith(\"m\"):\n","            self.quality=\"m\"; self.ext=rem[1:]\n","        else:\n","            self.quality=\"\"; self.ext=rem\n","    def as_str(self): return f\"{self.root}{self.quality}{self.ext}\"\n","\n","def transpose_one(c:str, interval:int)->str:\n","    e = ExtChord(c); rv = VAL.get(e.root, None)\n","    if rv is None: return c\n","    new_root = REV[(rv - interval) % 12]\n","    return f\"{new_root}{e.quality}{e.ext}\"\n","\n","def auto_interval_to_C(seq:List[str]):\n","    # Estima tonalidad media por raÃ­ces; devuelve semitonos para llevar a Do.\n","    roots = [VAL.get(ExtChord(c).root) for c in seq if VAL.get(ExtChord(c).root) is not None]\n","    if not roots: return 0\n","    mean = int(round(sum(roots)/len(roots))) % 12\n","    return mean  # intervalo para restar\n","\n","# --- Helpers: indexado y mÃ¡scara ---\n","def encode(seq:List[str]):\n","    ids = [CH2IDX.get(c, UNK) for c in seq][:MAX_LEN]\n","    if len(ids)<MAX_LEN: ids += [PAD]*(MAX_LEN-len(ids))\n","    return ids\n","\n","def attn_mask(ids:List[int]): return [1 if t!=PAD else 0 for t in ids]\n","\n","# --- PredicciÃ³n top-k con auto-transposiciÃ³n a Do y temperatura ---\n","@torch.no_grad()\n","def predict_topk_original_key(seq_orig:List[str], k:int=10, temperature:float=1.0)->List[Tuple[str,float]]:\n","    # 1) Normaliza y estima tonalidad; transpone a Do para modelo.\n","    seq_norm = [norm_ch(x) for x in seq_orig]\n","    interval = auto_interval_to_C(seq_norm)\n","    seq_C = [transpose_one(x, interval) for x in seq_norm]\n","    # 2) Codifica y prepara mÃ¡scara.\n","    ids = encode(seq_C); msk = attn_mask(ids)\n","    x = torch.tensor([ids], dtype=torch.long, device=device)\n","    a = torch.tensor([msk], dtype=torch.long, device=device)\n","    # 3) Forward y extracciÃ³n en la Ãºltima posiciÃ³n vÃ¡lida.\n","    T = int(sum(msk)) if any(msk) else 1\n","    logits = MODEL(x, attention_mask=a)[0, T-1, :]\n","    if temperature>0: logits = logits / float(temperature)\n","    probs = F.softmax(logits, dim=-1)\n","    top = torch.topk(probs, k=min(k, probs.numel()))\n","    idxs = top.indices.tolist(); pr = [float(v) for v in top.values.tolist()]\n","    chords_C = [IDX2CH.get(str(i), f\"<{i}>\") for i in idxs]\n","    # 4) Des-transpone a tonalidad original para mostrar.\n","    chords_orig = [transpose_one(c, -interval) for c in chords_C]\n","    return list(zip(chords_orig, pr))"]},{"cell_type":"markdown","source":["## UI Gradio"],"metadata":{"id":"XC_SIGPvc4-Q"}},{"cell_type":"code","source":["# Celda 2 â€” Gradio (layout 2x5 estable, \"Secuencia construida\" con |, C mayor por defecto, clave fija)\n","import gradio as gr, re, torch\n","\n","# ---------- UI helpers ----------\n","ROOT_DISPLAY = [\n","    (\"C (Do)\",\"C\"), (\"C# (Do#)\",\"C#\"), (\"Db (Reb)\",\"Db\"),\n","    (\"D (Re)\",\"D\"), (\"D# (Re#)\",\"D#\"), (\"Eb (Mib)\",\"Eb\"),\n","    (\"E (Mi)\",\"E\"), (\"F (Fa)\",\"F\"), (\"F# (Fa#)\",\"F#\"), (\"Gb (Solb)\",\"Gb\"),\n","    (\"G (Sol)\",\"G\"), (\"G# (Sol#)\",\"G#\"), (\"Ab (Lab)\",\"Ab\"),\n","    (\"A (La)\",\"A\"), (\"A# (La#)\",\"A#\"), (\"Bb (Sib)\",\"Bb\"),\n","    (\"B (Si)\",\"B\")\n","]\n","VARIANTS = [(\"mayor\",\"\"), (\"menor\",\"m\"), (\"7\",\"7\"), (\"maj7\",\"maj7\"),\n","            (\"sus2\",\"sus2\"), (\"sus4\",\"sus4\"), (\"add9\",\"add9\"), (\"6\",\"6\")]\n","\n","def render_seq_bar(seq):      # barra compacta con separador |\n","    return \" | \".join(seq) if seq else \"\"\n","\n","def medals_topk(chords_probs):\n","    medals = [\"ðŸ¥‡\",\"ðŸ¥ˆ\",\"ðŸ¥‰\"] + [\"\"]*7\n","    out = []\n","    for i,(c,p) in enumerate(chords_probs[:10]):\n","        out.append(f\"{medals[i]} {c} ({p*100:.2f}%)\".strip())\n","    return (out + [\"\"]*10)[:10]\n","\n","def fanout_button_labels(labels10):  # 10 -> 10 updates\n","    labels10 = (labels10 + [\"\"]*10)[:10]\n","    return [gr.update(value=l) for l in labels10]\n","\n","# ---------- PredicciÃ³n con clave fija ----------\n","@torch.no_grad()\n","def predict_topk_with_interval(seq_orig, k:int=10, temperature:float=1.0, interval:int=None):\n","    # Usa los helpers cargados en Celda 1: norm_ch, transpose_one, encode, attn_mask, MODEL, IDX2CH\n","    seq_norm = [norm_ch(x) for x in seq_orig]\n","    use_interval = auto_interval_to_C(seq_norm) if interval is None else int(interval)\n","    seq_C = [transpose_one(x, use_interval) for x in seq_norm]\n","    ids = encode(seq_C); msk = attn_mask(ids)\n","    x = torch.tensor([ids], dtype=torch.long, device=device)\n","    a = torch.tensor([msk], dtype=torch.long, device=device)\n","    T = int(sum(msk)) if any(msk) else 1\n","    logits = MODEL(x, attention_mask=a)[0, T-1, :]\n","    if temperature > 0: logits = logits / float(temperature)\n","    probs = torch.softmax(logits, dim=-1)\n","    top = torch.topk(probs, k=min(k, probs.numel()))\n","    idxs = top.indices.tolist(); pr = [float(v) for v in top.values.tolist()]\n","    chords_C = [IDX2CH.get(str(i), f\"<{i}>\") for i in idxs]\n","    chords_orig = [transpose_one(c, -use_interval) for c in chords_C]\n","    return list(zip(chords_orig, pr))\n","\n","def labels_topk(seq, temp, key_interval):\n","    top = predict_topk_with_interval(seq, k=10, temperature=temp, interval=key_interval)\n","    return medals_topk(top), top\n","\n","# ---------- Acciones ----------\n","def add_by_dropdown(seq, key_interval, root_label, var_label, temp):\n","    root = dict(ROOT_DISPLAY)[root_label]\n","    suf  = dict(VARIANTS)[var_label]\n","    chord = f\"{root}{suf}\"\n","    seq2 = seq + [chord]\n","    # fija clave si no existe todavÃ­a: raÃ­z del primer acorde\n","    key2 = VAL[ExtChord(chord).root] if key_interval is None else key_interval\n","    labels, top = labels_topk(seq2, temp, key2)\n","    return [seq2, key2, render_seq_bar(seq2), *fanout_button_labels(labels), top]\n","\n","def add_from_top(seq, key_interval, top, which, temp):\n","    if not top or which >= len(top):\n","        labels, top2 = labels_topk(seq, temp, key_interval) if seq else ([\"\"]*10, [])\n","        return [seq, key_interval, render_seq_bar(seq), *fanout_button_labels(labels), top2]\n","    chosen = top[which][0]\n","    seq2 = seq + [chosen]\n","    key2 = key_interval\n","    if key2 is None:  # si es el primer acorde aÃ±adido desde top-10, fija clave con su raÃ­z\n","        key2 = VAL.get(ExtChord(chosen).root, 0)\n","    labels, top2 = labels_topk(seq2, temp, key2)\n","    return [seq2, key2, render_seq_bar(seq2), *fanout_button_labels(labels), top2]\n","\n","def pop_one(seq, key_interval, temp):\n","    seq2 = seq[:-1] if seq else []\n","    key2 = None if len(seq2) == 0 else key_interval\n","    labels, top = labels_topk(seq2, temp, key2) if seq2 else ([\"\"]*10, [])\n","    return [seq2, key2, render_seq_bar(seq2), *fanout_button_labels(labels), top]\n","\n","def reset_all():\n","    return [[], None, \"\", *fanout_button_labels([\"\"]*10), []]\n","\n","def on_temp_change(seq, key_interval, t):\n","    if not seq:\n","        return [*fanout_button_labels([\"\"]*10), []]\n","    labels, top = labels_topk(seq, t, key_interval)\n","    return [*fanout_button_labels(labels), top]\n","\n","def init_buttons():\n","    # si quieres, puedes dejarlo vacÃ­o; mantenemos sugerencias base con seq vacÃ­a y clave indefinida\n","    labels, top = labels_topk([], 1.0, None)\n","    return [*fanout_button_labels(labels), top]\n","\n","# ---------- ConstrucciÃ³n de la UI ----------\n","with gr.Blocks(title=\"API_PREDICCIÃ“N - Gradio\") as demo:\n","    # CSS para grid 2x5 estable (no 4-1-4-1)\n","    gr.HTML(\"\"\"\n","    <style>\n","    #row_top1, #row_top2 { display: grid; grid-template-columns: repeat(5, 1fr); gap: 12px; }\n","    #row_top1 button, #row_top2 button { width: 100%; }\n","    </style>\n","    \"\"\")\n","    gr.Markdown(\"\"\"\n","### ðŸ§© Modelo interactivo - PredicciÃ³n de secuencias de acordes\n","- Selecciona la **raÃ­z** y **variante** del primer acorde.\n","- AÃ±ade acordes a la secuencia utilizando los **botones de la derecha**.\n","- **Borrar** elimina el Ãºltimo; **Reset** reinicia.\n","\"\"\")\n","\n","    with gr.Row():\n","        # Izquierda: selects + acciones\n","        with gr.Column(scale=6):\n","            root_dd = gr.Dropdown([r for r,_ in ROOT_DISPLAY], value=\"C (Do)\", label=\"RaÃ­z\")\n","            var_dd  = gr.Dropdown([v for v,_ in VARIANTS],   value=\"mayor\",  label=\"Variante\")\n","            with gr.Row():\n","                btn_add = gr.Button(\"AÃ±adir\", variant=\"primary\")\n","                btn_pop = gr.Button(\"Borrar\")\n","                btn_rst = gr.Button(\"Reset\")\n","        # Derecha: Top-10 (2x5) + barra \"Secuencia construida\"\n","        with gr.Column(scale=6):\n","            gr.Markdown(\"#### AÃ±adir\")\n","            with gr.Row(elem_id=\"row_top1\"):\n","                btns_row1 = [gr.Button(\"\", scale=1) for _ in range(5)]\n","            with gr.Row(elem_id=\"row_top2\"):\n","                btns_row2 = [gr.Button(\"\", scale=1) for _ in range(5)]\n","            btns = btns_row1 + btns_row2\n","            seq_bar = gr.Textbox(value=\"\", label=\"Secuencia construida\", interactive=False)\n","\n","    # Slider de temperatura (debajo)\n","    with gr.Row():\n","        temp = gr.Slider(0.1, 2.0, value=1.0, step=0.05, label=\"Temperature\")\n","\n","    # Estados\n","    seq_state = gr.State([])     # acordes en tonalidad original\n","    key_state = gr.State(None)   # intervalo fijo (se fija al primer acorde); None = sin fijar\n","    top_state = gr.State([])     # [(ch, prob), ...]\n","\n","    # ---- Enlaces de eventos ----\n","    demo.load(init_buttons, inputs=None, outputs=[*btns, top_state])\n","\n","    btn_add.click(add_by_dropdown,\n","                  inputs=[seq_state, key_state, root_dd, var_dd, temp],\n","                  outputs=[seq_state, key_state, seq_bar, *btns, top_state])\n","\n","    btn_pop.click(lambda s,k,t: pop_one(s,k,t),\n","                  inputs=[seq_state, key_state, temp],\n","                  outputs=[seq_state, key_state, seq_bar, *btns, top_state])\n","\n","    btn_rst.click(lambda: reset_all(),\n","                  inputs=None,\n","                  outputs=[seq_state, key_state, seq_bar, *btns, top_state])\n","\n","    for i, b in enumerate(btns):\n","        b.click(lambda s,k,top,t,i=i: add_from_top(s, k, top, i, t),\n","                inputs=[seq_state, key_state, top_state, temp],\n","                outputs=[seq_state, key_state, seq_bar, *btns, top_state])\n","\n","    temp.change(on_temp_change,\n","                inputs=[seq_state, key_state, temp],\n","                outputs=[*btns, top_state])\n","\n","demo.launch(share=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599},"id":"TbPGKrjAc6qa","executionInfo":{"status":"ok","timestamp":1755795448288,"user_tz":-120,"elapsed":5518,"user":{"displayName":"Carlos Romero","userId":"09804593201902616528"}},"outputId":"80969f12-037f-4887-eb94-6688c74678ff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","* To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":2}]}]}